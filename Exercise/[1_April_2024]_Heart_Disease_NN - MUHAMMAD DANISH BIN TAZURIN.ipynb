{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1q_qKIV2t2u"
      },
      "source": [
        "#Import all library needed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,BatchNormalization, Dropout\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "#confusion matrix visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### 1. Link notebook with google drive and access data from your personal Gdrive\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "### 2.Set the data path for dataset and model location (ex: model_loc = \"/content/gdrive/My Drive/Dataset/\")\n",
        "dataset_dir = \"/content/gdrive/My Drive/Datasets/\"\n",
        "model_loc = \"/content/gdrive/My Drive/Models/\"\n",
        "\n",
        "print(os.listdir(dataset_dir))\n",
        "data = pd.read_csv(dataset_dir+'heart.csv')"
      ],
      "metadata": {
        "id": "WazdlOZefP88",
        "outputId": "45aa5070-5db1-401e-e356-68a8d7a31f85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "['heart.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZADep6q2t3D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0199fb1-9cb6-498f-be61-cc1db4f82ab9"
      },
      "source": [
        "### 3. Insert Exploratory data analysis (EDA) steps to analyze and investigate datasets.\n",
        "\n",
        "# 1. Data Summary\n",
        "print(\"Data Summary:\")\n",
        "print(data.head())\n",
        "print(\"\\nData Info:\")\n",
        "print(data.info())\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(data.describe())\n",
        "\n",
        "# 2. Data Cleaning\n",
        "# Check for missing values\n",
        "print(\"\\nMissing Values:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# Check for duplicate rows\n",
        "duplicate_rows = data[data.duplicated()]\n",
        "print(\"\\nDuplicate Rows:\")\n",
        "print(duplicate_rows)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Summary:\n",
            "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
            "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
            "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
            "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
            "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
            "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
            "\n",
            "   ca  thal  target  \n",
            "0   0     1       1  \n",
            "1   0     2       1  \n",
            "2   0     2       1  \n",
            "3   0     2       1  \n",
            "4   0     2       1  \n",
            "\n",
            "Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       303 non-null    int64  \n",
            " 1   sex       303 non-null    int64  \n",
            " 2   cp        303 non-null    int64  \n",
            " 3   trestbps  303 non-null    int64  \n",
            " 4   chol      303 non-null    int64  \n",
            " 5   fbs       303 non-null    int64  \n",
            " 6   restecg   303 non-null    int64  \n",
            " 7   thalach   303 non-null    int64  \n",
            " 8   exang     303 non-null    int64  \n",
            " 9   oldpeak   303 non-null    float64\n",
            " 10  slope     303 non-null    int64  \n",
            " 11  ca        303 non-null    int64  \n",
            " 12  thal      303 non-null    int64  \n",
            " 13  target    303 non-null    int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 33.3 KB\n",
            "None\n",
            "\n",
            "Descriptive Statistics:\n",
            "              age         sex          cp    trestbps        chol         fbs  \\\n",
            "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
            "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
            "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
            "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
            "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
            "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
            "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
            "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
            "\n",
            "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
            "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
            "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
            "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
            "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
            "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
            "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
            "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
            "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
            "\n",
            "             thal      target  \n",
            "count  303.000000  303.000000  \n",
            "mean     2.313531    0.544554  \n",
            "std      0.612277    0.498835  \n",
            "min      0.000000    0.000000  \n",
            "25%      2.000000    0.000000  \n",
            "50%      2.000000    1.000000  \n",
            "75%      3.000000    1.000000  \n",
            "max      3.000000    1.000000  \n",
            "\n",
            "Missing Values:\n",
            "age         0\n",
            "sex         0\n",
            "cp          0\n",
            "trestbps    0\n",
            "chol        0\n",
            "fbs         0\n",
            "restecg     0\n",
            "thalach     0\n",
            "exang       0\n",
            "oldpeak     0\n",
            "slope       0\n",
            "ca          0\n",
            "thal        0\n",
            "target      0\n",
            "dtype: int64\n",
            "\n",
            "Duplicate Rows:\n",
            "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
            "164   38    1   2       138   175    0        1      173      0      0.0   \n",
            "\n",
            "     slope  ca  thal  target  \n",
            "164      2   4     2       1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61ylkru32t27"
      },
      "source": [
        "### 4. What is the purpose of the code that sets a list of categorical variables\n",
        "### in a dataset and then casts those variables to the object data type using the astype() function?\n",
        "\n",
        "catagorialList = ['sex','cp','fbs','restecg','exang','ca','thal']\n",
        "for item in catagorialList:\n",
        "    data[item] = data[item].astype('object') #casting to object"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The astype() function is used by the code to transform a list of categorical variables in a dataset to the object data type. By clearly designating these variables as categorical, we can make sure that the encoding and analysis procedures handle them correctly."
      ],
      "metadata": {
        "id": "Sob9e12llrNr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNbqP4z32t3L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ca7934-f914-4eb5-f219-03e23bddf25b"
      },
      "source": [
        " ### 5. Create more data by categorical variable into indicator variables using 'get_dummies' function\n",
        "\n",
        "data = pd.get_dummies(data, drop_first=True)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-34-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-34-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-34-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-34-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-34-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n",
            "<ipython-input-34-76ef3ba0124a>:3: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  data = pd.get_dummies(data, drop_first=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhlOEgqg2t3i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b5f9472-0046-4f19-c718-59d8e5b8d54c"
      },
      "source": [
        "### 6. Explain line 3,4 and 5 and print the shape of x and y\n",
        "\n",
        "y = data['target'].values\n",
        "y = y.reshape(y.shape[0],1)\n",
        "x = data.drop(['target'],axis=1)\n",
        "\n",
        "print(\"Shape of x:\", x.shape)\n",
        "print(\"Shape of y:\", y.shape)\n",
        "##"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: (303, 21)\n",
            "Shape of y: (303, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Line 3: y = data['target'].values\n",
        "This line extracts the values of the column named 'target' from the DataFrame data and assigns them to the variable y.\n",
        "\n",
        "Line 4: y = y.reshape(y.shape[0],1)\n",
        "This line reshapes the array y to have a shape of (y.shape[0], 1), converting it from a 1D array to a 2D column vector.\n",
        "\n",
        "Line 5: x = data.drop(['target'],axis=1)\n",
        "This line creates a new DataFrame x by dropping the column named 'target' from the original DataFrame data."
      ],
      "metadata": {
        "id": "_3yokaiJkq-R"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEGdOBJu2t3o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "003d07aa-58aa-4e2e-d389-a37d03a4ffb4"
      },
      "source": [
        "### 7. Create a simple dataset and demonstrate the normalization code on the simple dataset\n",
        "\n",
        "data = pd.DataFrame({'A': [10, 20, 30], 'B': [100, 200, 300], 'C': [1000, 2000, 3000]})\n",
        "print('Original dataset:')\n",
        "print(data)\n",
        "\n",
        "minx = np.min(data)\n",
        "maxx = np.max(data)\n",
        "data_norm = (data - minx) / (maxx - minx)\n",
        "print('\\nNormalized dataset:')\n",
        "print(data_norm)\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset:\n",
            "    A    B     C\n",
            "0  10  100  1000\n",
            "1  20  200  2000\n",
            "2  30  300  3000\n",
            "\n",
            "Normalized dataset:\n",
            "     A    B    C\n",
            "0  0.0  0.0  0.0\n",
            "1  0.5  0.5  0.5\n",
            "2  1.0  1.0  1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### 8. Describe the heart dataset after implementing the min max normalization\n",
        "#Normalize data (range 0 - 1)\n",
        "minx = np.min(x)\n",
        "maxx = np.max(x)\n",
        "x = (x - minx) / (maxx - minx)\n",
        "x.head()"
      ],
      "metadata": {
        "id": "asoFBQaumuKA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "b87daa60-6f39-4268-c0e4-44521e52c9ea"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.min(axis=None) will return a scalar min over the entire DataFrame. To retain the old behavior, use 'frame.min(axis=0)' or just 'frame.min()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:86: FutureWarning: In a future version, DataFrame.max(axis=None) will return a scalar max over the entire DataFrame. To retain the old behavior, use 'frame.max(axis=0)' or just 'frame.max()'\n",
            "  return reduction(axis=axis, out=out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age  trestbps      chol   thalach   oldpeak  slope  sex_1  cp_1  cp_2  \\\n",
              "0  0.708333  0.481132  0.244292  0.603053  0.370968    0.0    1.0   0.0   0.0   \n",
              "1  0.166667  0.339623  0.283105  0.885496  0.564516    0.0    1.0   0.0   1.0   \n",
              "2  0.250000  0.339623  0.178082  0.770992  0.225806    1.0    0.0   1.0   0.0   \n",
              "3  0.562500  0.245283  0.251142  0.816794  0.129032    1.0    1.0   1.0   0.0   \n",
              "4  0.583333  0.245283  0.520548  0.702290  0.096774    1.0    0.0   0.0   0.0   \n",
              "\n",
              "   cp_3  ...  restecg_1  restecg_2  exang_1  ca_1  ca_2  ca_3  ca_4  thal_1  \\\n",
              "0   1.0  ...        0.0        0.0      0.0   0.0   0.0   0.0   0.0     1.0   \n",
              "1   0.0  ...        1.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "2   0.0  ...        0.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "3   0.0  ...        1.0        0.0      0.0   0.0   0.0   0.0   0.0     0.0   \n",
              "4   0.0  ...        1.0        0.0      1.0   0.0   0.0   0.0   0.0     0.0   \n",
              "\n",
              "   thal_2  thal_3  \n",
              "0     0.0     0.0  \n",
              "1     1.0     0.0  \n",
              "2     1.0     0.0  \n",
              "3     1.0     0.0  \n",
              "4     1.0     0.0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c75099f8-0c32-4b62-a035-b1b462a230c5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalach</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_1</th>\n",
              "      <th>cp_2</th>\n",
              "      <th>cp_3</th>\n",
              "      <th>...</th>\n",
              "      <th>restecg_1</th>\n",
              "      <th>restecg_2</th>\n",
              "      <th>exang_1</th>\n",
              "      <th>ca_1</th>\n",
              "      <th>ca_2</th>\n",
              "      <th>ca_3</th>\n",
              "      <th>ca_4</th>\n",
              "      <th>thal_1</th>\n",
              "      <th>thal_2</th>\n",
              "      <th>thal_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.708333</td>\n",
              "      <td>0.481132</td>\n",
              "      <td>0.244292</td>\n",
              "      <td>0.603053</td>\n",
              "      <td>0.370968</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.283105</td>\n",
              "      <td>0.885496</td>\n",
              "      <td>0.564516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.339623</td>\n",
              "      <td>0.178082</td>\n",
              "      <td>0.770992</td>\n",
              "      <td>0.225806</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.251142</td>\n",
              "      <td>0.816794</td>\n",
              "      <td>0.129032</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.245283</td>\n",
              "      <td>0.520548</td>\n",
              "      <td>0.702290</td>\n",
              "      <td>0.096774</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c75099f8-0c32-4b62-a035-b1b462a230c5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c75099f8-0c32-4b62-a035-b1b462a230c5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c75099f8-0c32-4b62-a035-b1b462a230c5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7e45dfbd-f304-4ef3-b680-726b57b2607e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e45dfbd-f304-4ef3-b680-726b57b2607e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7e45dfbd-f304-4ef3-b680-726b57b2607e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "x"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The heart dataset will first undergo min-max normalization, after which the values of each feature will be scaled to a range of 0 to 1. By ensuring that each feature contributes equally to the analysis, this normalization keeps characteristics with higher magnitudes from taking center stage in the model.\n",
        "\n",
        "The given code determines each feature in the dataset's minimum and maximum values (x). Next, it uses the min-max normalization formula to scale each feature's value to fall between 0 and 1. Lastly, it uses the head() function to show the first few rows of the normalized dataset.\n",
        "\n",
        "In conclusion, the heart dataset is ready for additional analysis or modeling as, following min-max normalization, all of its feature values will be scaled to a range between 0 and 1."
      ],
      "metadata": {
        "id": "ar8Rhtd8m1Oj"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvykedw82t3u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b590be7-c8b1-4c1f-b6ad-e60c1523e632"
      },
      "source": [
        "### 9. Modify the code to split the dataset into train and test (train 70%, val 20% and test 10%).\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "# re-create train and validation set\n",
        "x_train, x_val, y_train, y_val  = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
        "# train 70%, validation 20%, test 10%\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(181, 21)\n",
            "(61, 21)\n",
            "(61, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Pwz5A_j2t30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7f5d470-0cb0-41cf-f1a0-b31813d2a078"
      },
      "source": [
        "### 10. What is the purpose of each layer in the neural network created using the Sequential() function with 64, 32, and 1 neurons,\n",
        "### respectively, and softmax and sigmoid activation functions?\n",
        "\n",
        "model = Sequential() #Allow us to create model layer by layer\n",
        "model.add(Dense(64, input_dim=21, activation='softmax')) #Softmax turn number data into probabilities which sum to 1\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.add(Dense(1, activation='sigmoid')) # produce probability value (number between 0 or 1)\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 64)                1408      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3521 (13.75 KB)\n",
            "Trainable params: 3521 (13.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Input Layer (Dense with 64 neurons and softmax activation):\n",
        "It processes the input data, converting it into probabilities that sum to 1.\n",
        "Helps the model understand the input data's distribution.\n",
        "\n",
        "2. Hidden Layer (Dense with 32 neurons and softmax activation):\n",
        "It performs further processing on the data, extracting more complex features.\n",
        "Also converts outputs into probabilities.\n",
        "\n",
        "3. Output Layer (Dense with 1 neuron and sigmoid activation):\n",
        "Produces the final prediction or probability value.\n",
        "Sigmoid activation ensures the output is between 0 and 1, suitable for binary classification tasks."
      ],
      "metadata": {
        "id": "pbuyumryoV2K"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0pM4z_OQfNi"
      },
      "source": [
        "### 11. This code compiles a neural network model with a mean squared error loss function, the Adam optimizer with a learning rate of 0.01,\n",
        "### and accuracy as a performance metric. What does each of these components mean, and how do they affect the model training and performance?\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999,epsilon=1e-07, amsgrad=False,name='Adam'),\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss Function ('mse' - Mean Squared Error):\n",
        "It measures how far the model's predictions are from the actual values.\n",
        "For regression tasks, like predicting house prices, we want to minimize this error.\n",
        "\n",
        "Optimizer (Adam with learning rate 0.01):\n",
        "It adjusts the model's internal parameters (weights) to minimize the loss.\n",
        "Adam is a popular optimizer, and the learning rate (0.01) controls how big the updates to the parameters are.\n",
        "Higher learning rates make bigger updates, but may overshoot the best values. Lower rates take smaller steps but converge more slowly.\n",
        "\n",
        "Metrics (Accuracy):\n",
        "It tells us how well the model is doing during training and testing.\n",
        "Accuracy measures the proportion of correct predictions out of all predictions.\n",
        "For classification tasks, like identifying images of cats and dogs, we want high accuracy.\n",
        "\n",
        "In summary, the chosen components of the model compilation affect how the model learns and performs during training:\n",
        "\n",
        "The loss function guides the model towards the correct predictions by penalizing errors.\n",
        "The optimizer determines how the model's weights are updated to minimize the loss function.\n",
        "The choice of metrics provides insight into the model's performance and helps in evaluating its accuracy."
      ],
      "metadata": {
        "id": "78kauKiGpQGU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unxSIBnZ2t36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ce4ab7-6345-4d64-9ca0-3f8dcb4a0266"
      },
      "source": [
        "# start the model training\n",
        "output = []\n",
        "early = EarlyStopping(monitor='val_acc', patience=400, mode='auto')\n",
        "checkpoint = ModelCheckpoint(model_loc+\"heart_disease_best_model.hdf5\", monitor='val_acc', verbose=0, save_best_only=True, mode='auto', save_freq='epoch')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.01, patience=100, verbose=1, mode='auto', min_lr=0.001)\n",
        "callbacks_list = [early]\n",
        "\n",
        "output = model.fit(x_train, y_train,validation_data=(x_val,y_val), epochs=1000, batch_size=16, verbose=1, callbacks=callbacks_list)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 1s 22ms/step - loss: 0.2491 - acc: 0.5580 - val_loss: 0.2495 - val_acc: 0.5246\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2467 - acc: 0.5580 - val_loss: 0.2487 - val_acc: 0.5246\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2449 - acc: 0.5580 - val_loss: 0.2471 - val_acc: 0.5246\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2423 - acc: 0.5580 - val_loss: 0.2412 - val_acc: 0.5246\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2355 - acc: 0.5580 - val_loss: 0.2335 - val_acc: 0.5246\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2260 - acc: 0.5580 - val_loss: 0.2216 - val_acc: 0.5246\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2123 - acc: 0.7127 - val_loss: 0.2042 - val_acc: 0.7869\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1949 - acc: 0.8398 - val_loss: 0.1906 - val_acc: 0.8033\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1781 - acc: 0.8232 - val_loss: 0.1725 - val_acc: 0.8361\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1625 - acc: 0.8232 - val_loss: 0.1645 - val_acc: 0.8361\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1512 - acc: 0.8398 - val_loss: 0.1626 - val_acc: 0.8033\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1398 - acc: 0.8619 - val_loss: 0.1502 - val_acc: 0.8033\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1329 - acc: 0.8564 - val_loss: 0.1500 - val_acc: 0.7869\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1238 - acc: 0.8729 - val_loss: 0.1580 - val_acc: 0.7705\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1193 - acc: 0.8674 - val_loss: 0.1487 - val_acc: 0.7869\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1125 - acc: 0.8729 - val_loss: 0.1531 - val_acc: 0.7869\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1091 - acc: 0.8729 - val_loss: 0.1443 - val_acc: 0.7869\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1039 - acc: 0.8785 - val_loss: 0.1522 - val_acc: 0.7869\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0998 - acc: 0.8729 - val_loss: 0.1545 - val_acc: 0.7869\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0959 - acc: 0.8840 - val_loss: 0.1496 - val_acc: 0.7869\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0939 - acc: 0.8950 - val_loss: 0.1520 - val_acc: 0.8033\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0899 - acc: 0.8950 - val_loss: 0.1522 - val_acc: 0.8197\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0874 - acc: 0.8950 - val_loss: 0.1588 - val_acc: 0.8033\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0827 - acc: 0.9006 - val_loss: 0.1486 - val_acc: 0.8197\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0821 - acc: 0.9006 - val_loss: 0.1538 - val_acc: 0.8197\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0799 - acc: 0.9061 - val_loss: 0.1629 - val_acc: 0.7869\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0764 - acc: 0.9116 - val_loss: 0.1509 - val_acc: 0.8197\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0707 - acc: 0.9227 - val_loss: 0.1508 - val_acc: 0.8197\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0665 - acc: 0.9282 - val_loss: 0.1529 - val_acc: 0.8197\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0634 - acc: 0.9282 - val_loss: 0.1578 - val_acc: 0.8033\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0599 - acc: 0.9392 - val_loss: 0.1641 - val_acc: 0.8033\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0562 - acc: 0.9503 - val_loss: 0.1611 - val_acc: 0.8033\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0538 - acc: 0.9503 - val_loss: 0.1650 - val_acc: 0.8033\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0521 - acc: 0.9558 - val_loss: 0.1644 - val_acc: 0.8033\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0521 - acc: 0.9448 - val_loss: 0.1646 - val_acc: 0.8033\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0501 - acc: 0.9558 - val_loss: 0.1706 - val_acc: 0.8033\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0469 - acc: 0.9558 - val_loss: 0.1696 - val_acc: 0.8033\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0460 - acc: 0.9558 - val_loss: 0.1708 - val_acc: 0.8033\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0453 - acc: 0.9613 - val_loss: 0.1743 - val_acc: 0.7869\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0428 - acc: 0.9613 - val_loss: 0.1752 - val_acc: 0.8033\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0408 - acc: 0.9669 - val_loss: 0.1768 - val_acc: 0.7869\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0397 - acc: 0.9669 - val_loss: 0.1773 - val_acc: 0.7869\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0390 - acc: 0.9669 - val_loss: 0.1803 - val_acc: 0.7869\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0388 - acc: 0.9669 - val_loss: 0.1841 - val_acc: 0.7869\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0430 - acc: 0.9558 - val_loss: 0.1829 - val_acc: 0.7869\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0394 - acc: 0.9613 - val_loss: 0.1846 - val_acc: 0.8033\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0391 - acc: 0.9669 - val_loss: 0.1870 - val_acc: 0.7869\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0365 - acc: 0.9669 - val_loss: 0.1849 - val_acc: 0.7869\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0352 - acc: 0.9669 - val_loss: 0.1869 - val_acc: 0.7869\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0351 - acc: 0.9669 - val_loss: 0.1873 - val_acc: 0.7869\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0348 - acc: 0.9669 - val_loss: 0.1878 - val_acc: 0.7869\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0345 - acc: 0.9669 - val_loss: 0.1881 - val_acc: 0.7869\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0343 - acc: 0.9669 - val_loss: 0.1891 - val_acc: 0.7869\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0341 - acc: 0.9669 - val_loss: 0.1896 - val_acc: 0.7869\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0340 - acc: 0.9669 - val_loss: 0.1901 - val_acc: 0.7869\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0339 - acc: 0.9669 - val_loss: 0.1903 - val_acc: 0.7869\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0338 - acc: 0.9669 - val_loss: 0.1913 - val_acc: 0.7869\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0336 - acc: 0.9669 - val_loss: 0.1904 - val_acc: 0.7869\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0336 - acc: 0.9669 - val_loss: 0.1914 - val_acc: 0.7869\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0335 - acc: 0.9669 - val_loss: 0.1921 - val_acc: 0.7869\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0335 - acc: 0.9669 - val_loss: 0.1919 - val_acc: 0.7869\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0333 - acc: 0.9669 - val_loss: 0.1933 - val_acc: 0.7869\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0333 - acc: 0.9669 - val_loss: 0.1927 - val_acc: 0.7869\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0332 - acc: 0.9669 - val_loss: 0.1932 - val_acc: 0.7869\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0330 - acc: 0.9669 - val_loss: 0.1932 - val_acc: 0.7869\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0331 - acc: 0.9669 - val_loss: 0.1931 - val_acc: 0.7869\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0329 - acc: 0.9669 - val_loss: 0.1938 - val_acc: 0.7869\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0329 - acc: 0.9669 - val_loss: 0.1937 - val_acc: 0.7869\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0329 - acc: 0.9669 - val_loss: 0.1941 - val_acc: 0.7869\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0328 - acc: 0.9669 - val_loss: 0.1940 - val_acc: 0.7869\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0328 - acc: 0.9669 - val_loss: 0.1945 - val_acc: 0.7869\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0327 - acc: 0.9669 - val_loss: 0.1945 - val_acc: 0.7869\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0327 - acc: 0.9669 - val_loss: 0.1948 - val_acc: 0.7869\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0326 - acc: 0.9669 - val_loss: 0.1939 - val_acc: 0.7869\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0327 - acc: 0.9669 - val_loss: 0.1938 - val_acc: 0.7869\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0326 - acc: 0.9669 - val_loss: 0.1949 - val_acc: 0.7869\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0326 - acc: 0.9669 - val_loss: 0.1952 - val_acc: 0.7869\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0325 - acc: 0.9669 - val_loss: 0.1954 - val_acc: 0.7869\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0325 - acc: 0.9669 - val_loss: 0.1956 - val_acc: 0.7869\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0325 - acc: 0.9669 - val_loss: 0.1959 - val_acc: 0.7869\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0325 - acc: 0.9669 - val_loss: 0.1958 - val_acc: 0.7869\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0324 - acc: 0.9669 - val_loss: 0.1959 - val_acc: 0.7869\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0325 - acc: 0.9669 - val_loss: 0.1958 - val_acc: 0.7869\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0324 - acc: 0.9669 - val_loss: 0.1967 - val_acc: 0.7869\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0323 - acc: 0.9669 - val_loss: 0.1959 - val_acc: 0.7869\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0323 - acc: 0.9669 - val_loss: 0.1960 - val_acc: 0.7869\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0323 - acc: 0.9669 - val_loss: 0.1960 - val_acc: 0.7869\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0323 - acc: 0.9669 - val_loss: 0.1963 - val_acc: 0.7869\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0323 - acc: 0.9669 - val_loss: 0.1963 - val_acc: 0.7869\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0322 - acc: 0.9669 - val_loss: 0.1967 - val_acc: 0.7869\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0323 - acc: 0.9669 - val_loss: 0.1971 - val_acc: 0.7869\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0322 - acc: 0.9669 - val_loss: 0.1967 - val_acc: 0.7869\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0322 - acc: 0.9669 - val_loss: 0.1966 - val_acc: 0.7869\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0322 - acc: 0.9669 - val_loss: 0.1979 - val_acc: 0.7869\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0322 - acc: 0.9669 - val_loss: 0.1979 - val_acc: 0.7869\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0322 - acc: 0.9669 - val_loss: 0.1974 - val_acc: 0.7869\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0321 - acc: 0.9669 - val_loss: 0.1973 - val_acc: 0.7869\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0321 - acc: 0.9669 - val_loss: 0.1974 - val_acc: 0.7869\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0321 - acc: 0.9669 - val_loss: 0.1970 - val_acc: 0.7869\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0321 - acc: 0.9669 - val_loss: 0.1967 - val_acc: 0.7869\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0321 - acc: 0.9669 - val_loss: 0.1967 - val_acc: 0.7869\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0321 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0321 - acc: 0.9669 - val_loss: 0.1975 - val_acc: 0.7869\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0320 - acc: 0.9669 - val_loss: 0.1967 - val_acc: 0.7869\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0321 - acc: 0.9669 - val_loss: 0.1970 - val_acc: 0.7869\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0320 - acc: 0.9669 - val_loss: 0.1974 - val_acc: 0.7869\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0320 - acc: 0.9669 - val_loss: 0.1972 - val_acc: 0.7869\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0320 - acc: 0.9669 - val_loss: 0.1970 - val_acc: 0.7869\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0320 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0320 - acc: 0.9669 - val_loss: 0.1967 - val_acc: 0.7869\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0320 - acc: 0.9669 - val_loss: 0.1970 - val_acc: 0.7869\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0320 - acc: 0.9669 - val_loss: 0.1971 - val_acc: 0.7869\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.1968 - val_acc: 0.7869\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.1970 - val_acc: 0.7869\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.1970 - val_acc: 0.7869\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.1967 - val_acc: 0.7869\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.1967 - val_acc: 0.7869\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.1972 - val_acc: 0.7869\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.1964 - val_acc: 0.7869\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0318 - acc: 0.9669 - val_loss: 0.1965 - val_acc: 0.7869\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.1972 - val_acc: 0.7869\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0318 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0318 - acc: 0.9669 - val_loss: 0.1968 - val_acc: 0.7869\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0318 - acc: 0.9669 - val_loss: 0.1964 - val_acc: 0.7869\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0318 - acc: 0.9669 - val_loss: 0.1960 - val_acc: 0.7869\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0318 - acc: 0.9669 - val_loss: 0.1962 - val_acc: 0.7869\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0318 - acc: 0.9669 - val_loss: 0.1971 - val_acc: 0.7869\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0318 - acc: 0.9669 - val_loss: 0.1968 - val_acc: 0.7869\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0318 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0318 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0318 - acc: 0.9669 - val_loss: 0.1976 - val_acc: 0.7869\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0318 - acc: 0.9669 - val_loss: 0.1974 - val_acc: 0.7869\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0318 - acc: 0.9669 - val_loss: 0.1963 - val_acc: 0.7869\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0317 - acc: 0.9669 - val_loss: 0.1966 - val_acc: 0.7869\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0317 - acc: 0.9669 - val_loss: 0.1970 - val_acc: 0.7869\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0317 - acc: 0.9669 - val_loss: 0.1967 - val_acc: 0.7869\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0317 - acc: 0.9669 - val_loss: 0.1973 - val_acc: 0.7869\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0317 - acc: 0.9669 - val_loss: 0.1972 - val_acc: 0.7869\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0317 - acc: 0.9669 - val_loss: 0.1972 - val_acc: 0.7869\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0317 - acc: 0.9669 - val_loss: 0.1971 - val_acc: 0.7869\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1974 - val_acc: 0.7869\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1965 - val_acc: 0.7869\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0329 - acc: 0.9613 - val_loss: 0.1982 - val_acc: 0.7869\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0327 - acc: 0.9669 - val_loss: 0.2004 - val_acc: 0.7869\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0323 - acc: 0.9669 - val_loss: 0.1998 - val_acc: 0.7869\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.1960 - val_acc: 0.7869\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0317 - acc: 0.9669 - val_loss: 0.1929 - val_acc: 0.7869\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0317 - acc: 0.9669 - val_loss: 0.1933 - val_acc: 0.7869\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0317 - acc: 0.9669 - val_loss: 0.1965 - val_acc: 0.7869\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0317 - acc: 0.9669 - val_loss: 0.1961 - val_acc: 0.7869\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1961 - val_acc: 0.7869\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1963 - val_acc: 0.7869\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1966 - val_acc: 0.7869\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1965 - val_acc: 0.7869\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1967 - val_acc: 0.7869\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1961 - val_acc: 0.7869\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1968 - val_acc: 0.7869\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1966 - val_acc: 0.7869\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1961 - val_acc: 0.7869\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1965 - val_acc: 0.7869\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0315 - acc: 0.9669 - val_loss: 0.1968 - val_acc: 0.7869\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0315 - acc: 0.9669 - val_loss: 0.1968 - val_acc: 0.7869\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0315 - acc: 0.9669 - val_loss: 0.1965 - val_acc: 0.7869\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0315 - acc: 0.9669 - val_loss: 0.1967 - val_acc: 0.7869\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0315 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0315 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0315 - acc: 0.9669 - val_loss: 0.1973 - val_acc: 0.7869\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0315 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0315 - acc: 0.9669 - val_loss: 0.1967 - val_acc: 0.7869\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0315 - acc: 0.9669 - val_loss: 0.1979 - val_acc: 0.7869\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0315 - acc: 0.9669 - val_loss: 0.1983 - val_acc: 0.7869\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0315 - acc: 0.9669 - val_loss: 0.1979 - val_acc: 0.7869\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0314 - acc: 0.9669 - val_loss: 0.1970 - val_acc: 0.7869\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0314 - acc: 0.9669 - val_loss: 0.1961 - val_acc: 0.7869\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0313 - acc: 0.9669 - val_loss: 0.1957 - val_acc: 0.7869\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0312 - acc: 0.9669 - val_loss: 0.1965 - val_acc: 0.7869\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1974 - val_acc: 0.7869\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0313 - acc: 0.9669 - val_loss: 0.1980 - val_acc: 0.7869\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0312 - acc: 0.9669 - val_loss: 0.1979 - val_acc: 0.7869\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0324 - acc: 0.9613 - val_loss: 0.1968 - val_acc: 0.7869\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.2033 - val_acc: 0.7705\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.2009 - val_acc: 0.7869\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0316 - acc: 0.9669 - val_loss: 0.1996 - val_acc: 0.7869\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0315 - acc: 0.9669 - val_loss: 0.1976 - val_acc: 0.7869\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0314 - acc: 0.9669 - val_loss: 0.1968 - val_acc: 0.7869\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0314 - acc: 0.9669 - val_loss: 0.1961 - val_acc: 0.7869\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0314 - acc: 0.9669 - val_loss: 0.1964 - val_acc: 0.7869\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0314 - acc: 0.9669 - val_loss: 0.1962 - val_acc: 0.7869\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0314 - acc: 0.9669 - val_loss: 0.1962 - val_acc: 0.7869\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0313 - acc: 0.9669 - val_loss: 0.1965 - val_acc: 0.7869\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0313 - acc: 0.9669 - val_loss: 0.1972 - val_acc: 0.7869\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0313 - acc: 0.9669 - val_loss: 0.1975 - val_acc: 0.7869\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0313 - acc: 0.9669 - val_loss: 0.1970 - val_acc: 0.7869\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0313 - acc: 0.9669 - val_loss: 0.1961 - val_acc: 0.7869\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0313 - acc: 0.9669 - val_loss: 0.1966 - val_acc: 0.7869\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0313 - acc: 0.9669 - val_loss: 0.1968 - val_acc: 0.7869\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0312 - acc: 0.9669 - val_loss: 0.1975 - val_acc: 0.7869\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0312 - acc: 0.9669 - val_loss: 0.1971 - val_acc: 0.7869\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0312 - acc: 0.9669 - val_loss: 0.1975 - val_acc: 0.7869\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0311 - acc: 0.9669 - val_loss: 0.1964 - val_acc: 0.7869\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0311 - acc: 0.9669 - val_loss: 0.1958 - val_acc: 0.7869\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0310 - acc: 0.9669 - val_loss: 0.1959 - val_acc: 0.7869\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0309 - acc: 0.9669 - val_loss: 0.1964 - val_acc: 0.7869\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0319 - acc: 0.9669 - val_loss: 0.1946 - val_acc: 0.7869\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0314 - acc: 0.9669 - val_loss: 0.2013 - val_acc: 0.7705\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0314 - acc: 0.9669 - val_loss: 0.1998 - val_acc: 0.7869\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0315 - acc: 0.9669 - val_loss: 0.1968 - val_acc: 0.7869\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0310 - acc: 0.9669 - val_loss: 0.1937 - val_acc: 0.7869\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0309 - acc: 0.9669 - val_loss: 0.1943 - val_acc: 0.7705\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0309 - acc: 0.9669 - val_loss: 0.1956 - val_acc: 0.7869\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0308 - acc: 0.9669 - val_loss: 0.1962 - val_acc: 0.7869\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0307 - acc: 0.9669 - val_loss: 0.1971 - val_acc: 0.7869\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0307 - acc: 0.9669 - val_loss: 0.1985 - val_acc: 0.7869\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0306 - acc: 0.9669 - val_loss: 0.1972 - val_acc: 0.7705\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0302 - acc: 0.9669 - val_loss: 0.1978 - val_acc: 0.7705\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0297 - acc: 0.9669 - val_loss: 0.2052 - val_acc: 0.7705\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0295 - acc: 0.9669 - val_loss: 0.2049 - val_acc: 0.7541\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0302 - acc: 0.9669 - val_loss: 0.1985 - val_acc: 0.7869\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0303 - acc: 0.9669 - val_loss: 0.1983 - val_acc: 0.7869\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0301 - acc: 0.9669 - val_loss: 0.1976 - val_acc: 0.7869\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0297 - acc: 0.9669 - val_loss: 0.1969 - val_acc: 0.7869\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0294 - acc: 0.9669 - val_loss: 0.1968 - val_acc: 0.7869\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0291 - acc: 0.9669 - val_loss: 0.1967 - val_acc: 0.7869\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0283 - acc: 0.9669 - val_loss: 0.1955 - val_acc: 0.7869\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0302 - acc: 0.9613 - val_loss: 0.1957 - val_acc: 0.7869\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0322 - acc: 0.9613 - val_loss: 0.2015 - val_acc: 0.7869\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0341 - acc: 0.9613 - val_loss: 0.1882 - val_acc: 0.7869\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0350 - acc: 0.9558 - val_loss: 0.1973 - val_acc: 0.7869\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0292 - acc: 0.9669 - val_loss: 0.1999 - val_acc: 0.7869\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0272 - acc: 0.9669 - val_loss: 0.2036 - val_acc: 0.7869\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0268 - acc: 0.9669 - val_loss: 0.2014 - val_acc: 0.7869\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0267 - acc: 0.9669 - val_loss: 0.1996 - val_acc: 0.7869\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0261 - acc: 0.9669 - val_loss: 0.1990 - val_acc: 0.7869\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0256 - acc: 0.9669 - val_loss: 0.1987 - val_acc: 0.7869\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0253 - acc: 0.9669 - val_loss: 0.1979 - val_acc: 0.7869\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0250 - acc: 0.9669 - val_loss: 0.1971 - val_acc: 0.7869\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0246 - acc: 0.9669 - val_loss: 0.1944 - val_acc: 0.7869\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0246 - acc: 0.9669 - val_loss: 0.1940 - val_acc: 0.7869\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0240 - acc: 0.9669 - val_loss: 0.1920 - val_acc: 0.7869\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0235 - acc: 0.9669 - val_loss: 0.1907 - val_acc: 0.7869\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0232 - acc: 0.9669 - val_loss: 0.1883 - val_acc: 0.7869\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0227 - acc: 0.9669 - val_loss: 0.1859 - val_acc: 0.8033\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0225 - acc: 0.9669 - val_loss: 0.1854 - val_acc: 0.8033\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0217 - acc: 0.9669 - val_loss: 0.1854 - val_acc: 0.8033\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0223 - acc: 0.9669 - val_loss: 0.1862 - val_acc: 0.8033\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9724 - val_loss: 0.1869 - val_acc: 0.8033\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0207 - acc: 0.9724 - val_loss: 0.1850 - val_acc: 0.8033\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0200 - acc: 0.9724 - val_loss: 0.1863 - val_acc: 0.8033\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0194 - acc: 0.9724 - val_loss: 0.1895 - val_acc: 0.7869\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0195 - acc: 0.9724 - val_loss: 0.1911 - val_acc: 0.7869\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0209 - acc: 0.9779 - val_loss: 0.1956 - val_acc: 0.7869\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0209 - acc: 0.9669 - val_loss: 0.1915 - val_acc: 0.7869\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0181 - acc: 0.9724 - val_loss: 0.1907 - val_acc: 0.7869\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0185 - acc: 0.9779 - val_loss: 0.1919 - val_acc: 0.7869\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0187 - acc: 0.9724 - val_loss: 0.1915 - val_acc: 0.7869\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0187 - acc: 0.9724 - val_loss: 0.1945 - val_acc: 0.7869\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0177 - acc: 0.9724 - val_loss: 0.1938 - val_acc: 0.7869\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0163 - acc: 0.9779 - val_loss: 0.1993 - val_acc: 0.7869\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0164 - acc: 0.9779 - val_loss: 0.1998 - val_acc: 0.7869\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0166 - acc: 0.9779 - val_loss: 0.1946 - val_acc: 0.7869\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0161 - acc: 0.9779 - val_loss: 0.2052 - val_acc: 0.7705\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0156 - acc: 0.9779 - val_loss: 0.2132 - val_acc: 0.7541\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0156 - acc: 0.9724 - val_loss: 0.2128 - val_acc: 0.7541\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0155 - acc: 0.9724 - val_loss: 0.2204 - val_acc: 0.7705\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0163 - acc: 0.9779 - val_loss: 0.2245 - val_acc: 0.7377\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0157 - acc: 0.9779 - val_loss: 0.2080 - val_acc: 0.7869\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0147 - acc: 0.9779 - val_loss: 0.2154 - val_acc: 0.7705\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0141 - acc: 0.9779 - val_loss: 0.2102 - val_acc: 0.7705\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0131 - acc: 0.9890 - val_loss: 0.2118 - val_acc: 0.7705\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0132 - acc: 0.9834 - val_loss: 0.2122 - val_acc: 0.7705\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.0145 - acc: 0.9724 - val_loss: 0.2099 - val_acc: 0.7705\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0144 - acc: 0.9724 - val_loss: 0.2124 - val_acc: 0.7705\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0123 - acc: 0.9890 - val_loss: 0.2134 - val_acc: 0.7705\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0118 - acc: 0.9890 - val_loss: 0.2147 - val_acc: 0.7705\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0122 - acc: 0.9779 - val_loss: 0.2157 - val_acc: 0.7705\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0116 - acc: 0.9890 - val_loss: 0.2203 - val_acc: 0.7541\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0115 - acc: 0.9834 - val_loss: 0.2170 - val_acc: 0.7705\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0109 - acc: 0.9890 - val_loss: 0.2192 - val_acc: 0.7705\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0113 - acc: 0.9834 - val_loss: 0.2144 - val_acc: 0.7705\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0100 - acc: 0.9945 - val_loss: 0.2165 - val_acc: 0.7705\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0107 - acc: 0.9945 - val_loss: 0.2175 - val_acc: 0.7705\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0097 - acc: 0.9890 - val_loss: 0.2185 - val_acc: 0.7705\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0106 - acc: 0.9834 - val_loss: 0.2193 - val_acc: 0.7705\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0107 - acc: 0.9890 - val_loss: 0.2146 - val_acc: 0.7705\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0092 - acc: 0.9945 - val_loss: 0.2145 - val_acc: 0.7705\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0095 - acc: 0.9890 - val_loss: 0.2182 - val_acc: 0.7705\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0091 - acc: 0.9945 - val_loss: 0.2114 - val_acc: 0.7705\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0090 - acc: 0.9890 - val_loss: 0.2137 - val_acc: 0.7705\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0082 - acc: 0.9945 - val_loss: 0.2096 - val_acc: 0.7869\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0087 - acc: 0.9890 - val_loss: 0.2124 - val_acc: 0.7705\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0098 - acc: 0.9890 - val_loss: 0.2092 - val_acc: 0.7705\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0145 - acc: 0.9834 - val_loss: 0.2119 - val_acc: 0.7705\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0100 - acc: 0.9890 - val_loss: 0.2123 - val_acc: 0.7705\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0081 - acc: 0.9945 - val_loss: 0.2139 - val_acc: 0.7705\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0107 - acc: 0.9890 - val_loss: 0.2085 - val_acc: 0.7705\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0096 - acc: 0.9890 - val_loss: 0.2134 - val_acc: 0.7705\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0090 - acc: 0.9945 - val_loss: 0.2170 - val_acc: 0.7705\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0077 - acc: 0.9945 - val_loss: 0.2088 - val_acc: 0.7869\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0072 - acc: 0.9945 - val_loss: 0.2132 - val_acc: 0.7541\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0076 - acc: 0.9945 - val_loss: 0.2133 - val_acc: 0.7541\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0077 - acc: 0.9945 - val_loss: 0.2122 - val_acc: 0.7541\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0069 - acc: 0.9945 - val_loss: 0.2139 - val_acc: 0.7705\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0081 - acc: 0.9945 - val_loss: 0.2151 - val_acc: 0.7705\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0074 - acc: 0.9945 - val_loss: 0.2146 - val_acc: 0.7705\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0067 - acc: 0.9945 - val_loss: 0.2144 - val_acc: 0.7705\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0068 - acc: 0.9945 - val_loss: 0.2164 - val_acc: 0.7705\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0067 - acc: 0.9945 - val_loss: 0.2143 - val_acc: 0.7705\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0065 - acc: 0.9945 - val_loss: 0.2155 - val_acc: 0.7705\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0065 - acc: 0.9945 - val_loss: 0.2174 - val_acc: 0.7705\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0112 - acc: 0.9834 - val_loss: 0.2204 - val_acc: 0.7705\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0093 - acc: 0.9890 - val_loss: 0.2128 - val_acc: 0.7705\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0095 - acc: 0.9890 - val_loss: 0.2122 - val_acc: 0.7705\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0087 - acc: 0.9890 - val_loss: 0.2043 - val_acc: 0.7705\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0076 - acc: 0.9890 - val_loss: 0.2042 - val_acc: 0.7705\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0068 - acc: 0.9945 - val_loss: 0.2071 - val_acc: 0.7705\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0062 - acc: 0.9890 - val_loss: 0.2087 - val_acc: 0.7705\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0068 - acc: 0.9890 - val_loss: 0.2078 - val_acc: 0.7705\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0068 - acc: 0.9945 - val_loss: 0.1989 - val_acc: 0.7869\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0072 - acc: 0.9945 - val_loss: 0.2056 - val_acc: 0.7705\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0053 - acc: 0.9945 - val_loss: 0.2075 - val_acc: 0.7705\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0061 - acc: 0.9945 - val_loss: 0.2080 - val_acc: 0.7705\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0054 - acc: 0.9945 - val_loss: 0.2068 - val_acc: 0.7705\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0056 - acc: 0.9945 - val_loss: 0.2056 - val_acc: 0.7705\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0054 - acc: 0.9945 - val_loss: 0.2093 - val_acc: 0.7705\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0059 - acc: 0.9890 - val_loss: 0.2127 - val_acc: 0.7705\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0075 - acc: 0.9945 - val_loss: 0.2007 - val_acc: 0.7869\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0068 - acc: 0.9945 - val_loss: 0.1980 - val_acc: 0.7705\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0052 - acc: 0.9945 - val_loss: 0.2018 - val_acc: 0.7705\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0050 - acc: 0.9945 - val_loss: 0.2011 - val_acc: 0.7869\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0053 - acc: 0.9945 - val_loss: 0.2069 - val_acc: 0.7705\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0047 - acc: 0.9945 - val_loss: 0.2060 - val_acc: 0.7705\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0059 - acc: 0.9890 - val_loss: 0.2066 - val_acc: 0.7869\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0049 - acc: 0.9945 - val_loss: 0.2048 - val_acc: 0.7869\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0058 - acc: 0.9945 - val_loss: 0.1998 - val_acc: 0.7869\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0048 - acc: 0.9945 - val_loss: 0.2056 - val_acc: 0.7869\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0050 - acc: 0.9945 - val_loss: 0.2067 - val_acc: 0.7869\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0050 - acc: 0.9945 - val_loss: 0.2058 - val_acc: 0.7869\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0056 - acc: 0.9945 - val_loss: 0.2043 - val_acc: 0.7869\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0045 - acc: 0.9945 - val_loss: 0.2067 - val_acc: 0.7869\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0065 - acc: 0.9945 - val_loss: 0.2030 - val_acc: 0.7869\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0054 - acc: 0.9945 - val_loss: 0.2029 - val_acc: 0.7869\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0077 - acc: 0.9945 - val_loss: 0.2054 - val_acc: 0.7869\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0064 - acc: 0.9945 - val_loss: 0.2058 - val_acc: 0.7869\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0058 - acc: 0.9945 - val_loss: 0.1952 - val_acc: 0.8033\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0041 - acc: 0.9945 - val_loss: 0.2000 - val_acc: 0.7869\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0060 - acc: 0.9945 - val_loss: 0.2018 - val_acc: 0.7869\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0063 - acc: 0.9945 - val_loss: 0.1932 - val_acc: 0.8033\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0069 - acc: 0.9945 - val_loss: 0.1985 - val_acc: 0.7869\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0054 - acc: 0.9945 - val_loss: 0.1984 - val_acc: 0.7869\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0045 - acc: 0.9945 - val_loss: 0.1953 - val_acc: 0.8033\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0042 - acc: 0.9945 - val_loss: 0.1975 - val_acc: 0.8033\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0046 - acc: 0.9945 - val_loss: 0.2008 - val_acc: 0.7869\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0055 - acc: 0.9945 - val_loss: 0.2020 - val_acc: 0.7869\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0042 - acc: 0.9945 - val_loss: 0.2030 - val_acc: 0.7869\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0044 - acc: 0.9945 - val_loss: 0.2014 - val_acc: 0.7869\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0040 - acc: 0.9945 - val_loss: 0.2037 - val_acc: 0.7869\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0041 - acc: 0.9945 - val_loss: 0.2059 - val_acc: 0.7869\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0049 - acc: 0.9945 - val_loss: 0.2060 - val_acc: 0.7869\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0059 - acc: 0.9945 - val_loss: 0.2044 - val_acc: 0.7869\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0055 - acc: 0.9945 - val_loss: 0.1976 - val_acc: 0.7869\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0040 - acc: 0.9945 - val_loss: 0.2000 - val_acc: 0.7869\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0049 - acc: 0.9945 - val_loss: 0.1979 - val_acc: 0.8033\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0057 - acc: 0.9890 - val_loss: 0.2020 - val_acc: 0.7869\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0070 - acc: 0.9890 - val_loss: 0.2051 - val_acc: 0.7869\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0042 - acc: 0.9945 - val_loss: 0.1962 - val_acc: 0.8033\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0040 - acc: 0.9945 - val_loss: 0.1963 - val_acc: 0.8033\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0041 - acc: 0.9945 - val_loss: 0.2030 - val_acc: 0.7869\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0051 - acc: 0.9945 - val_loss: 0.1971 - val_acc: 0.8033\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0042 - acc: 0.9945 - val_loss: 0.1973 - val_acc: 0.8033\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0044 - acc: 0.9945 - val_loss: 0.1996 - val_acc: 0.7869\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0033 - acc: 0.9945 - val_loss: 0.2022 - val_acc: 0.7705\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0033 - acc: 0.9945 - val_loss: 0.2026 - val_acc: 0.7869\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0039 - acc: 0.9945 - val_loss: 0.2014 - val_acc: 0.7869\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0053 - acc: 0.9890 - val_loss: 0.2038 - val_acc: 0.7869\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0038 - acc: 0.9945 - val_loss: 0.2045 - val_acc: 0.7869\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0033 - acc: 0.9945 - val_loss: 0.2032 - val_acc: 0.7869\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 0.2047 - val_acc: 0.7869\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0038 - acc: 0.9945 - val_loss: 0.2055 - val_acc: 0.7869\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0041 - acc: 0.9945 - val_loss: 0.2060 - val_acc: 0.7869\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0031 - acc: 0.9945 - val_loss: 0.2065 - val_acc: 0.7869\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0041 - acc: 0.9945 - val_loss: 0.2072 - val_acc: 0.7869\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0037 - acc: 0.9945 - val_loss: 0.2067 - val_acc: 0.7869\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.2078 - val_acc: 0.7705\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.2079 - val_acc: 0.7869\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0038 - acc: 0.9945 - val_loss: 0.2077 - val_acc: 0.7869\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0037 - acc: 0.9945 - val_loss: 0.2076 - val_acc: 0.7869\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.2088 - val_acc: 0.7869\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0031 - acc: 0.9945 - val_loss: 0.2081 - val_acc: 0.7869\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0039 - acc: 0.9945 - val_loss: 0.2097 - val_acc: 0.7705\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0029 - acc: 0.9945 - val_loss: 0.2090 - val_acc: 0.7869\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0032 - acc: 0.9945 - val_loss: 0.2114 - val_acc: 0.7705\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0050 - acc: 0.9945 - val_loss: 0.2089 - val_acc: 0.7869\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0086 - acc: 0.9890 - val_loss: 0.2007 - val_acc: 0.7869\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0027 - acc: 0.9945 - val_loss: 0.1984 - val_acc: 0.8033\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0033 - acc: 0.9945 - val_loss: 0.2029 - val_acc: 0.7869\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0037 - acc: 0.9945 - val_loss: 0.2052 - val_acc: 0.7869\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.2056 - val_acc: 0.7869\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0031 - acc: 0.9945 - val_loss: 0.2058 - val_acc: 0.7869\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.2073 - val_acc: 0.7869\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0032 - acc: 0.9945 - val_loss: 0.2044 - val_acc: 0.7869\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0046 - acc: 0.9945 - val_loss: 0.2046 - val_acc: 0.7869\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0049 - acc: 0.9945 - val_loss: 0.2103 - val_acc: 0.7705\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0037 - acc: 0.9945 - val_loss: 0.2023 - val_acc: 0.7869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sYpy54d2t4H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "4605faf6-5116-45f7-ff07-f2208937b561"
      },
      "source": [
        "### 12. What does the plot generated by this code represent?\n",
        "\n",
        "plt.plot(output.history['acc'])\n",
        "plt.plot(output.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "#plt.savefig('Accuracy.png',dpi=100) #to save the image\n",
        "plt.show()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot shows how the model's accuracy changes over epochs during training and validation."
      ],
      "metadata": {
        "id": "pO5hoAJirrvB"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIrcCZ8P2t4N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "3aa7c420-61a4-4855-907e-8f7c2875eb8d"
      },
      "source": [
        "### 13. Plot code for the model loss. You can refer to the plot code for model accuracy above.\n",
        "plt.plot(output.history['loss'])\n",
        "plt.plot(output.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "#plt.savefig('Loss.png',dpi=100) #to save the image\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KTWzuJM12t4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e273bcb-077e-45e1-9f0b-7c1594b65ce2"
      },
      "source": [
        "### 14. What is the purpose of evaluating the model on the test dataset?\n",
        "\n",
        "#model.load_weights(model_loc+\"heart_disease_best_model.hdf5\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[0], scores[0]))\n",
        "print(\"loss:\", round(scores[0],2))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1270 - acc: 0.8689\n",
            "\n",
            "acc: 86.89%\n",
            "loss: 0.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the model on the test dataset helps to understand how well it performs on new, unseen data, providing a reliable estimate of its real-world performance."
      ],
      "metadata": {
        "id": "HQjxzUk2sb8p"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNYy0CRt2t4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a245906c-7ad2-49f3-db51-c802f1377945"
      },
      "source": [
        "#Display detailed prediction\n",
        "pred = model.predict(x_test)\n",
        "y = np.round(pred).astype(\"int16\")\n",
        "idx = 0\n",
        "ps = 0\n",
        "fl = 0\n",
        "for x in pred:\n",
        "    if y_test[idx]==y[idx]:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\"Result: \\033[92mPass\")\n",
        "        ps = ps+1\n",
        "    else:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\" Result: \\033[91mFail\")\n",
        "        fl = fl+1\n",
        "    idx = idx + 1\n",
        "print(\"\\033[30mRight Prediction :\",ps, \"Wrong Prediction :\",fl)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step\n",
            "\u001b[30mNo: 1 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 2 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 3 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 4 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 5 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 6 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 7 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 8 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 9 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 10 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 11 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 12 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 13 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 14 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 15 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 16 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 17 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 18 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 19 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 20 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 21 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 22 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 23 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 24 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 25 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 26 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 27 Actual: [0]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 28 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 29 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 30 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 31 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 32 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 33 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 34 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 35 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 36 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 37 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 38 Actual: [1]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 39 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 40 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 41 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 42 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 43 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 44 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 45 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 46 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 47 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 48 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 49 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 50 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 51 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 52 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 53 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 54 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 55 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 56 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 57 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 58 Actual: [1]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 59 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 60 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 61 Actual: [0]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mRight Prediction : 53 Wrong Prediction : 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHQBXNX5aYcn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "92568189-733a-438d-b60e-972f0df62a7e"
      },
      "source": [
        "### 15. What is Confusion Matrix and why you need it? Explain TP, FP, FN, TN.\n",
        "### 16. Explain the classification report produce.\n",
        "\n",
        "y_pred = y\n",
        "y_true = y_test\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "#cm = confusion_matrix(y_true, y_pred, labels=labels.astype('int'))\n",
        "f, ax=plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(cm,annot=True,linewidths=1.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.show()\n",
        "print()\n",
        "print(classification_report(y_true, y_pred, labels=[0,1]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86        29\n",
            "           1       0.88      0.88      0.88        32\n",
            "\n",
            "    accuracy                           0.87        61\n",
            "   macro avg       0.87      0.87      0.87        61\n",
            "weighted avg       0.87      0.87      0.87        61\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A confusion matrix is a table used to evaluate the performance of a classification model. It shows the counts of correct and incorrect predictions made by the model. The main components are:\n",
        "\n",
        "True Positives (TP): Correctly predicted positive cases.\n",
        "False Positives (FP): Incorrectly predicted positive cases.\n",
        "False Negatives (FN): Incorrectly predicted negative cases.\n",
        "True Negatives (TN): Correctly predicted negative cases.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "16n2nLJ3slzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision: Proportion of true positive predictions out of all positive predictions.\n",
        "\n",
        "Recall (or Sensitivity): Proportion of true positive predictions out of all actual positives.\n",
        "\n",
        "F1-score: Harmonic mean of precision and recall, providing a balanced measure.\n",
        "\n",
        "Support: Number of actual occurrences of each class."
      ],
      "metadata": {
        "id": "opffpEuxs01g"
      }
    }
  ]
}